{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import model.sdes as sdes\n",
    "import model.generate as generate\n",
    "import model.cifar_unet as cifar_unet\n",
    "import model.util as model_util\n",
    "from plot.plot import plot_mnist_digits\n",
    "from analysis.fid import compute_fid\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be8ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(range(100))\n",
    "branch_defs = [((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), 0.6166166166166166, 1), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), 0.5985985985985985, 0.6166166166166166), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), 0.5465465465465466, 0.5985985985985985), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), 0.5415415415415415, 0.5465465465465466), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), 0.5135135135135135, 0.5415415415415415), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), 0.5045045045045045, 0.5135135135135135), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), 0.5025025025025025, 0.5045045045045045), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99), 0.4824824824824825, 0.5025025025025025), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99), 0.47347347347347346, 0.4824824824824825), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99), 0.45245245245245247, 0.47347347347347346), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99), 0.44344344344344344, 0.45245245245245247), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99), 0.4094094094094094, 0.44344344344344344), ((0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99), 0.3763763763763764, 0.4094094094094094), ((0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99), 0.36736736736736736, 0.3763763763763764), ((0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99), 0.36036036036036034, 0.36736736736736736), ((0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99), 0.2092092092092092, 0.36036036036036034), ((0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 22, 23, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99), 0.15, 0.2092092092092092), ((20, 24), 0.15, 0.5465465465465466), ((86,), 0, 0.6166166166166166), ((73,), 0, 0.5985985985985985), ((69,), 0, 0.5415415415415415), ((62,), 0, 0.5135135135135135), ((9,), 0, 0.5045045045045045), ((95,), 0, 0.5025025025025025), ((30,), 0, 0.4824824824824825), ((17,), 0, 0.47347347347347346), ((67,), 0, 0.45245245245245247), ((92,), 0, 0.44344344344344344), ((41,), 0, 0.4094094094094094), ((7,), 0, 0.3763763763763764), ((33,), 0, 0.36736736736736736), ((54,), 0, 0.36036036036036034), ((21,), 0, 0.2092092092092092), ((36,), 0, 0.15), ((60,), 0, 0.15), ((71,), 0, 0.15), ((61,), 0, 0.15), ((90,), 0, 0.15), ((82,), 0, 0.15), ((85,), 0, 0.15), ((25,), 0, 0.15), ((23,), 0, 0.15), ((24,), 0, 0.15), ((20,), 0, 0.15), ((27,), 0, 0.15), ((28,), 0, 0.15), ((89,), 0, 0.15), ((79,), 0, 0.15), ((94,), 0, 0.15), ((68,), 0, 0.15), ((26,), 0, 0.15), ((31,), 0, 0.15), ((63,), 0, 0.15), ((47,), 0, 0.15), ((4,), 0, 0.15), ((98,), 0, 0.15), ((51,), 0, 0.15), ((1,), 0, 0.15), ((59,), 0, 0.15), ((52,), 0, 0.15), ((96,), 0, 0.15), ((50,), 0, 0.15), ((8,), 0, 0.15), ((58,), 0, 0.15), ((55,), 0, 0.15), ((91,), 0, 0.15), ((93,), 0, 0.15), ((49,), 0, 0.15), ((12,), 0, 0.15), ((66,), 0, 0.15), ((2,), 0, 0.15), ((70,), 0, 0.15), ((83,), 0, 0.15), ((6,), 0, 0.15), ((53,), 0, 0.15), ((16,), 0, 0.15), ((19,), 0, 0.15), ((5,), 0, 0.15), ((32,), 0, 0.15), ((0,), 0, 0.15), ((43,), 0, 0.15), ((13,), 0, 0.15), ((18,), 0, 0.15), ((29,), 0, 0.15), ((48,), 0, 0.15), ((87,), 0, 0.15), ((88,), 0, 0.15), ((10,), 0, 0.15), ((39,), 0, 0.15), ((22,), 0, 0.15), ((56,), 0, 0.15), ((57,), 0, 0.15), ((40,), 0, 0.15), ((45,), 0, 0.15), ((42,), 0, 0.15), ((64,), 0, 0.15), ((75,), 0, 0.15), ((65,), 0, 0.15), ((46,), 0, 0.15), ((72,), 0, 0.15), ((74,), 0, 0.15), ((77,), 0, 0.15), ((78,), 0, 0.15), ((80,), 0, 0.15), ((84,), 0, 0.15), ((97,), 0, 0.15), ((35,), 0, 0.15), ((99,), 0, 0.15), ((76,), 0, 0.15), ((37,), 0, 0.15), ((81,), 0, 0.15), ((3,), 0, 0.15), ((11,), 0, 0.15), ((14,), 0, 0.15), ((15,), 0, 0.15), ((34,), 0, 0.15), ((38,), 0, 0.15), ((44,), 0, 0.15)]\n",
    "# branch_defs = [(tuple(classes), 0, 1)]\n",
    "\n",
    "# classes = [0, 53]\n",
    "# branch_defs = [\n",
    "#     ((0, 53), 0.5, 1),\n",
    "#     ((0,), 0, 0.5),\n",
    "#     ((53,), 0, 0.5)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e88168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARBranchDataset(torch.utils.data.IterableDataset):\n",
    "\n",
    "    def __init__(self, classes, branch_defs, batch_size, num_batches):\n",
    "        self.class_images = {}\n",
    "\n",
    "        cifar_dataset = torchvision.datasets.CIFAR100(\n",
    "            \"/gstore/scratch/u/tsenga5/datasets/CIFAR-100\", train=True\n",
    "        )\n",
    "        cifar_dataset.targets = np.array(cifar_dataset.targets)\n",
    "        for c in classes:\n",
    "            inds = cifar_dataset.targets == c\n",
    "            data = cifar_dataset.data[inds]\n",
    "            self.class_images[c] = (np.transpose(data, (0, 3, 1, 2)) / 256 * 2) - 1\n",
    "\n",
    "        self.branch_defs = branch_defs\n",
    "        self.branch_inds = np.tile(\n",
    "            np.arange(len(branch_defs)), int(np.ceil(num_batches / len(branch_defs)))\n",
    "        )[:num_batches]\n",
    "        self.branch_inds = np.random.permutation(self.branch_inds)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def get_batch(self, index):\n",
    "        classes, time_start, time_end = self.branch_defs[self.branch_inds[index]]\n",
    "        data = []\n",
    "        for _ in range(self.batch_size):\n",
    "            images = self.class_images[np.random.choice(classes)]\n",
    "            data.append(images[np.random.choice(len(images))])\n",
    "        data = np.stack(data)\n",
    "        times = (np.random.rand(self.batch_size) * (time_end - time_start)) + time_start\n",
    "        branch_inds = np.full(self.batch_size, self.branch_inds[index])\n",
    "        return torch.tensor(data), torch.tensor(times), torch.tensor(branch_inds)\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        num_batches = len(self)\n",
    "        if worker_info is None:\n",
    "            # In single-processing mode\n",
    "            start, end = 0, num_batches\n",
    "        else:\n",
    "            worker_id = worker_info.id\n",
    "            num_workers = worker_info.num_workers\n",
    "            shard_size = int(np.ceil(num_batches / num_workers))\n",
    "            start = shard_size * worker_id\n",
    "            end = min(start + shard_size, num_batches)\n",
    "        return (self.get_batch(i) for i in range(start, end))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.branch_inds)\n",
    "\n",
    "    def on_epoch_start(self):\n",
    "        self.branch_inds = np.random.permutation(self.branch_inds)\n",
    "        \n",
    "dataset = CIFARBranchDataset(classes, branch_defs, 16, 300)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=None, num_workers=2, collate_fn=lambda x: x\n",
    ")\n",
    "input_shape = next(iter(data_loader))[0].shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = torchvision.datasets.CIFAR100(\n",
    "#     \"/gstore/scratch/u/tsenga5/datasets/CIFAR-100\", train=True, transform=(lambda img: (np.transpose(np.asarray(img), (2, 0, 1)) / 256 * 2) - 1)\n",
    "# )\n",
    "\n",
    "# # Limit classes\n",
    "# dataset.targets = np.array(dataset.targets)\n",
    "# inds = np.isin(dataset.targets, classes)\n",
    "# dataset.data = dataset.data[inds]\n",
    "# dataset.targets = dataset.targets[inds]\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "# sample_x, sample_y = next(iter(data_loader))\n",
    "# input_shape = sample_x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a89ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this is currently rather inefficient; a decision-tree-style structure\n",
    "# would be better\n",
    "\n",
    "def class_time_to_branch(c, t):\n",
    "    \"\"\"\n",
    "    Given a class and a time (both scalars), return the\n",
    "    corresponding branch index.\n",
    "    \"\"\"\n",
    "    for i, branch_def in enumerate(branch_defs):\n",
    "        if c in branch_def[0] and t >= branch_def[1] and t <= branch_def[2]:\n",
    "            return i\n",
    "    raise ValueError(\"Undefined class and time\")\n",
    "        \n",
    "def class_time_to_branch_tensor(c, t):\n",
    "    \"\"\"\n",
    "    Given tensors of classes and a times, return the\n",
    "    corresponding branch indices as a tensor.\n",
    "    \"\"\"\n",
    "    return torch.tensor([\n",
    "        class_time_to_branch(c_i, t_i) for c_i, t_i in zip(c, t)\n",
    "    ], device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SDE and model\n",
    "sde = sdes.VariancePreservingSDE(0.1, 20, input_shape)\n",
    "\n",
    "t_limit = 1\n",
    "model = cifar_unet.MultitaskUNet(\n",
    "    len(branch_defs), t_limit=t_limit,\n",
    "    shared_layers=[True, True, True, True, True, True, True, False, False]\n",
    ").to(DEVICE)\n",
    "\n",
    "os.environ[\"MODEL_DIR\"] = \"/gstore/scratch/u/tsenga5/branched_diffusion/models/trained_models/cifar_continuous_branched_100classes_warm\"\n",
    "\n",
    "import model.train_continuous_model as train_continuous_model  # Import this AFTER setting environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b907a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cifar(\n",
    "    images, grid_size=(10, 5), scale=1, clip=False, title=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots CIFAR objects. No normalization will be done.\n",
    "    Arguments:\n",
    "        `images`: a B x 3 x 28 x 28 NumPy array of numbers between\n",
    "            0 and 1\n",
    "        `grid_size`: a pair of integers denoting the number of images\n",
    "            to plot horizontally and vertically (in that order); if\n",
    "            more digits are provided than spaces in the grid, leftover\n",
    "            digits will not be plotted; if fewer images are provided\n",
    "            than spaces in the grid, there will be at most one\n",
    "            unfinished row\n",
    "        `scale`: amount to scale figure size by\n",
    "        `clip`: if True, clip values to between 0 and 1\n",
    "        `title`: if given, title for the plot\n",
    "    \"\"\"\n",
    "    images = np.transpose(images, (0, 2, 3, 1))\n",
    "    if clip:\n",
    "        images = np.clip(images, 0, 1)\n",
    "\n",
    "    width, height = grid_size\n",
    "    num_images = len(images)\n",
    "    height = min(height, num_images // width)\n",
    "\n",
    "    figsize = (width * scale, (height * scale) + 0.5)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        ncols=width, nrows=height,\n",
    "        figsize=figsize, gridspec_kw={\"wspace\": 0, \"hspace\": 0}\n",
    "    )\n",
    "    if height == 1:\n",
    "        ax = [ax]\n",
    "    if width == 1:\n",
    "        ax = [[a] for a in ax]\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            index = i + (width * j)\n",
    "            ax[j][i].imshow(images[index], cmap=\"gray\", aspect=\"auto\", interpolation=None)\n",
    "            ax[j][i].axis(\"off\")\n",
    "    if title:\n",
    "        ax[0][0].set_title(title)\n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf57dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some images after running the SDE forward for different times\n",
    "time_steps = 4\n",
    "\n",
    "x0, _ = next(iter(data_loader))\n",
    "x0 = x0.cpu().numpy()\n",
    "\n",
    "plot_cifar((x0 + 1) / 2, grid_size=(8, 1), clip=True, title=\"t = 0\")\n",
    "x0 = torch.tensor(x0).to(DEVICE)\n",
    "for t in np.linspace(0.01, t_limit, time_steps):\n",
    "    xt, score = sde.forward(x0, torch.full(x0.shape[:1], t).to(DEVICE))\n",
    "    plot_cifar((xt.cpu().numpy() + 1) / 2, grid_size=(8, 1), clip=True, title=(\"t = %.2f\" % t))\n",
    "    \n",
    "# Show the transformation of the distribution of data to the prior distribution\n",
    "time_steps = 30\n",
    "\n",
    "all_t = np.linspace(0, t_limit, time_steps)\n",
    "all_xt = np.empty((len(all_t),) + x0.shape)\n",
    "for t_i, t in enumerate(all_t):\n",
    "    xt, _ = sde.forward(x0, torch.ones(len(x0)).to(DEVICE) * t)\n",
    "    all_xt[t_i] = xt.cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "cmap = plt.get_cmap(\"magma\")\n",
    "for t_i in range(len(all_t)):\n",
    "    ax.hist(np.ravel(all_xt[t_i]), bins=60, histtype=\"step\", color=cmap(t_i / len(all_t)), alpha=0.5, density=True)\n",
    "prior = sde.sample_prior(len(x0), torch.ones(len(x0)).to(DEVICE) * t).cpu().numpy()\n",
    "ax.hist(np.ravel(prior), bins=60, histtype=\"step\", color=\"blue\", linewidth=2, density=True, label=\"Sampled prior\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"p(x)\")\n",
    "ax.set_title(\"Evolution of p(x) over forward SDE\")\n",
    "ax.set_ylim((0, 3))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init = model_util.load_model(\n",
    "    cifar_unet.MultitaskUNet,\n",
    "    os.path.join(\n",
    "        \"/gstore/scratch/u/tsenga5/branched_diffusion/models/trained_models/\",\n",
    "        \"cifar_continuous_nobranch/1/last_ckpt.pth\"\n",
    "    )\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be5343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy over weights\n",
    "for module_name, module in model_init.named_children():\n",
    "    if module_name in (\"init_conv\", \"time_mlp\"):\n",
    "        model.get_submodule(module_name).load_state_dict(module.state_dict())\n",
    "    elif module_name in (\"mid\", \"final_res_blocks\", \"final_convs\"):\n",
    "        target_module = model.get_submodule(module_name)\n",
    "        for i in range(len(target_module)):\n",
    "            target_module[i].load_state_dict(module[0].state_dict())\n",
    "    elif module_name in (\"ups\", \"downs\"):\n",
    "        for layer_i in range(len(module)):\n",
    "            target_module = model.get_submodule(module_name)[layer_i]\n",
    "            for i in range(len(target_module)):\n",
    "                target_module[i].load_state_dict(module[layer_i][0].state_dict())\n",
    "    else:\n",
    "        raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460cd58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_continuous_model.train_ex.run(\n",
    "    \"train_branched_model\",\n",
    "    config_updates={\n",
    "        \"model\": model,\n",
    "        \"sde\": sde,\n",
    "        \"data_loader\": data_loader,\n",
    "        \"class_time_to_branch_index\": class_time_to_branch_tensor,\n",
    "        \"num_epochs\": 120,\n",
    "        \"learning_rate\": 0.00001,\n",
    "        \"t_limit\": t_limit,\n",
    "        \"loss_weighting_type\": \"empirical_norm\",\n",
    "        \"data_loader_returns_t_and_b\": True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_samples = {}\n",
    "for class_to_sample in classes:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    samples = generate.generate_continuous_branched_samples(\n",
    "        model, sde, class_to_sample, class_time_to_branch_tensor,\n",
    "        sampler=\"pc\", t_limit=t_limit\n",
    "    ).cpu().numpy()\n",
    "    gen_samples[class_to_sample] = samples\n",
    "    plot_cifar((samples + 1) / 2, grid_size=(10, 1), clip=True, title=None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_samples = {}\n",
    "for class_to_sample in classes:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    inds = np.where(dataset.targets == class_to_sample)[0]\n",
    "    sample_inds = np.random.choice(inds, size=200, replace=False)\n",
    "    samples = np.transpose((dataset.data[sample_inds] / 256 * 2) - 1, (0, 3, 1, 2))\n",
    "    true_samples[class_to_sample] = samples\n",
    "    plot_cifar((samples + 1) / 2, grid_size=(10, 1), title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute FID scores\n",
    "fid_scores = {}\n",
    "for class_to_sample in classes:\n",
    "    print(\"FID of %d\" % class_to_sample)\n",
    "    fid = compute_fid(gen_samples[class_to_sample], true_samples[class_to_sample])\n",
    "    print(\"FID: %.4f\" % fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
