{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import feature.scrna_dataset as scrna_dataset\n",
    "import model.sdes as sdes\n",
    "import model.generate as generate\n",
    "import model.scrna_ae as scrna_ae\n",
    "import model.util as model_util\n",
    "import analysis.fid as fid\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df22d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe528ba",
   "metadata": {},
   "source": [
    "### Define the branches and create the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3268176",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = False\n",
    "latent_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951177e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"/gstore/data/resbioai/tsenga5/branched_diffusion/data/scrna/covid_flu/processed/covid_flu_processed_reduced_genes.h5\"\n",
    "autoencoder_path = \"/gstore/data/resbioai/tsenga5/branched_diffusion/models/trained_models/scrna_vaes/covid_flu/covid_flu_processed_reduced_genes_ldvae_d%d/\" % latent_dim\n",
    "\n",
    "# models_base_path = \"/gstore/home/tsenga5/branched_diffusion/models/trained_models/scrna_covid_flu_continuous_latent_class_extension\"\n",
    "\n",
    "models_base_path = \"/gstore/scratch/u/tsenga5/branched_diffusion/models/trained_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this is currently rather inefficient; a decision-tree-style structure\n",
    "# would be better\n",
    "\n",
    "def class_time_to_branch(c, t, branch_defs):\n",
    "    \"\"\"\n",
    "    Given a class and a time (both scalars), return the\n",
    "    corresponding branch index.\n",
    "    \"\"\"\n",
    "    for i, branch_def in enumerate(branch_defs):\n",
    "        if c in branch_def[0] and t >= branch_def[1] and t <= branch_def[2]:\n",
    "            return i\n",
    "    raise ValueError(\"Undefined class and time\")\n",
    "        \n",
    "def class_time_to_branch_tensor(c, t, branch_defs):\n",
    "    \"\"\"\n",
    "    Given tensors of classes and a times, return the\n",
    "    corresponding branch indices as a tensor.\n",
    "    \"\"\"\n",
    "    return torch.tensor([\n",
    "        class_time_to_branch(c_i, t_i, branch_defs) for c_i, t_i in zip(c, t)\n",
    "    ], device=DEVICE)\n",
    "\n",
    "def class_to_class_index_tensor(c, classes):\n",
    "    \"\"\"\n",
    "    Given a tensor of classes, return the corresponding class indices\n",
    "    as a tensor.\n",
    "    \"\"\"\n",
    "    return torch.argmax(\n",
    "        (c[:, None] == torch.tensor(classes, device=c.device)).int(), dim=1\n",
    "    ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426efda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the branches\n",
    "classes_01 = [0, 1]\n",
    "branch_defs_01 = [((0, 1), 0.5795795795795796, 1), ((0,), 0, 0.5795795795795796), ((1,), 0, 0.5795795795795796)]\n",
    "\n",
    "classes_012 = [0, 1, 5]\n",
    "branch_defs_012 = [((0, 1, 5), 6.786786786786787e-01, 1), ((0, 1), 0.5795795795795796, 0.6786786786786787), ((5,), 0, 0.6786786786786787), ((0,), 0, 0.5795795795795796), ((1,), 0, 0.5795795795795796)]\n",
    "\n",
    "classes_2 = [5]\n",
    "branch_defs_2 = [((5,), 0, 0.6786786786786787)]\n",
    "\n",
    "# classes_012 = [0, 1, 2]\n",
    "# branch_defs_012 = [((0, 1, 2), 0.5795795795795796, 1), ((1, 2), 0.22922922922922923, 0.5795795795795796), ((2,), 0, 0.22922922922922923), ((0,), 0, 0.5795795795795796), ((1,), 0, 0.22922922922922923)]\n",
    "\n",
    "# classes_2 = [2]\n",
    "# branch_defs_2 = [((2,), 0, 0.22922922922922923)]\n",
    "\n",
    "# classes_012 = [0, 1, 3]\n",
    "# branch_defs_012 = [((0, 1, 3), 0.5795795795795796, 1), ((1, 3), 0.5085085085085085, 0.5795795795795796), ((3,), 0, 0.5085085085085085), ((0,), 0, 0.5795795795795796), ((1,), 0, 0.5085085085085085)]\n",
    "\n",
    "# classes_2 = [3]\n",
    "# branch_defs_2 = [((3,), 0, 0.5085085085085085)]\n",
    "\n",
    "dataset_01 = scrna_dataset.SingleCellDataset(data_file, autoencoder_path=(autoencoder_path if latent_space else None))\n",
    "# dataset_015 = scrna_dataset.SingleCellDataset(data_file, autoencoder_path=(autoencoder_path if latent_space else None))\n",
    "# dataset_5 = scrna_dataset.SingleCellDataset(data_file, autoencoder_path=(autoencoder_path if latent_space else None))\n",
    "dataset_012 = scrna_dataset.SingleCellDataset(data_file, autoencoder_path=(autoencoder_path if latent_space else None))\n",
    "dataset_2 = scrna_dataset.SingleCellDataset(data_file, autoencoder_path=(autoencoder_path if latent_space else None))\n",
    "\n",
    "# Limit classes\n",
    "inds_01 = np.isin(dataset_01.cell_cluster, classes_01)\n",
    "dataset_01.data = dataset_01.data[inds_01]\n",
    "dataset_01.cell_cluster = dataset_01.cell_cluster[inds_01]\n",
    "# inds_015 = np.isin(dataset_015.cell_cluster, classes_015)\n",
    "# dataset_015.data = dataset_015.data[inds_015]\n",
    "# dataset_015.cell_cluster = dataset_015.cell_cluster[inds_015]\n",
    "# inds_5 = np.isin(dataset_5.cell_cluster, classes_5)\n",
    "# dataset_5.data = dataset_5.data[inds_5]\n",
    "# dataset_5.cell_cluster = dataset_5.cell_cluster[inds_5]\n",
    "inds_012 = np.isin(dataset_012.cell_cluster, classes_012)\n",
    "dataset_012.data = dataset_012.data[inds_012]\n",
    "dataset_012.cell_cluster = dataset_012.cell_cluster[inds_012]\n",
    "inds_2 = np.isin(dataset_2.cell_cluster, classes_2)\n",
    "dataset_2.data = dataset_2.data[inds_2]\n",
    "dataset_2.cell_cluster = dataset_2.cell_cluster[inds_2]\n",
    "\n",
    "data_loader_01 = torch.utils.data.DataLoader(dataset_01, batch_size=128, shuffle=True, num_workers=0)\n",
    "# data_loader_015 = torch.utils.data.DataLoader(dataset_015, batch_size=128, shuffle=True, num_workers=0)\n",
    "# data_loader_5 = torch.utils.data.DataLoader(dataset_5, batch_size=128, shuffle=True, num_workers=0)\n",
    "data_loader_012 = torch.utils.data.DataLoader(dataset_012, batch_size=128, shuffle=True, num_workers=0)\n",
    "data_loader_2 = torch.utils.data.DataLoader(dataset_2, batch_size=128, shuffle=True, num_workers=0)\n",
    "input_shape = next(iter(data_loader_01))[0].shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SDE\n",
    "sde = sdes.VariancePreservingSDE(0.1, 5, input_shape)\n",
    "\n",
    "t_limit = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387aa61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"MODEL_DIR\"] = os.path.join(models_base_path, \"extension\")\n",
    "os.environ[\"MODEL_DIR\"] = \"/gstore/scratch/u/tsenga5/branched_diffusion/models/trained_models/extension\"\n",
    "\n",
    "import model.train_continuous_model as train_continuous_model  # Import this AFTER setting environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19ff6b",
   "metadata": {},
   "source": [
    "#### Train extra branch on branched model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_branch_def(branch_def, target_branch_defs):\n",
    "    \"\"\"\n",
    "    Given a particular branch definition (i.e. a triplet), and a\n",
    "    list of branch definitions, attempts to match that branch\n",
    "    definition to the corresponding entry in the list. This\n",
    "    mapping is based on whether or not the branch would need to be\n",
    "    retrained. The query `branch_def` is matched to a target within\n",
    "    `branch_defs` if the target's class indices are all present in\n",
    "    the query, and the query time is a sub-interval of the target\n",
    "    time.\n",
    "    Arguments:\n",
    "        `branch_def`: a branch definition (i.e. triplet of class index\n",
    "            tuple, start time, and end time)\n",
    "        `target_branch_defs`: a list of branch definitions\n",
    "    Returns the index of the matched branch definition in `branch_defs`,\n",
    "    or -1 if there is no suitable match found.\n",
    "    \"\"\"\n",
    "    for i, target_branch_def in enumerate(target_branch_defs):\n",
    "        if set(branch_def[0]).issuperset(set(target_branch_def[0])) \\\n",
    "            and branch_def[1] >= target_branch_def[1] \\\n",
    "            and branch_def[2] <= target_branch_def[2]:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701982d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "branched_model_1 = model_util.load_model(\n",
    "    scrna_ae.MultitaskResNet,\n",
    "    os.path.join(models_base_path, \"scrna_covid_flu_continuous_branched_2classes/1/last_ckpt.pth\")\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99ea13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the samples\n",
    "branched_samples_before = {}\n",
    "for class_to_sample in classes_01:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    sample = generate.generate_continuous_branched_samples(\n",
    "        branched_model_1, sde, class_to_sample,\n",
    "        lambda c, t: class_time_to_branch_tensor(c, t, branch_defs_01),\n",
    "        sampler=\"pc\", t_limit=t_limit, num_samples=1000, verbose=True\n",
    "    )\n",
    "    branched_samples_before[class_to_sample] = sample.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model and copy over parameters\n",
    "branched_model_2 = scrna_ae.MultitaskResNet(\n",
    "    len(branch_defs_012), input_shape[0], t_limit=t_limit\n",
    ").to(DEVICE)\n",
    "\n",
    "# Figure out which branches should be copied over to which ones\n",
    "branch_map_inds = [\n",
    "    map_branch_def(bd, branch_defs_01) for bd in branch_defs_012\n",
    "]\n",
    "\n",
    "# For each submodule, copy over the weights\n",
    "# Careful: this assumes a particular kind of architecture!\n",
    "modules_1 = dict(branched_model_1.named_children())\n",
    "modules_2 = dict(branched_model_2.named_children())\n",
    "\n",
    "for module_name in [\"layers\", \"time_embedders\"]:\n",
    "    for submodule_i, submodule in enumerate(modules_1[module_name]):\n",
    "        if len(submodule) == 1:\n",
    "            branched_model_2.get_submodule(module_name)[submodule_i].load_state_dict(\n",
    "                submodule.state_dict()\n",
    "            )\n",
    "        elif len(submodule) == len(branch_defs_01):\n",
    "            target_submodule_list = branched_model_2.get_submodule(module_name)[submodule_i]\n",
    "            for target_i, source_i in enumerate(branch_map_inds):\n",
    "                if source_i != -1:\n",
    "                    target_submodule_list[target_i].load_state_dict(\n",
    "                        submodule[source_i].state_dict()\n",
    "                    )\n",
    "                else:\n",
    "                    # Copy over some other branch for a warm start\n",
    "                    # We'll manually set it for now (TODO)\n",
    "                    source_i = -1  # Last branch\n",
    "                    target_submodule_list[target_i].load_state_dict(\n",
    "                        submodule[source_i].state_dict()\n",
    "                    )\n",
    "        else:\n",
    "            raise ValueError(\"Found module list of length %d\" % len(module_list))\n",
    "\n",
    "submodule = branched_model_1.get_submodule(\"last_linears\")\n",
    "target_submodule_list = branched_model_2.get_submodule(\"last_linears\")\n",
    "for target_i, source_i in enumerate(branch_map_inds):\n",
    "    if source_i != -1:\n",
    "        target_submodule_list[target_i].load_state_dict(\n",
    "            submodule[source_i].state_dict()\n",
    "        )\n",
    "    else:\n",
    "        # Copy over some other branch for a warm start\n",
    "        # We'll manually set it for now (TODO)\n",
    "        source_i = -1  # Last branch\n",
    "        target_submodule_list[target_i].load_state_dict(\n",
    "            submodule[source_i].state_dict()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6840fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the samples again to make sure match-up was done correctly\n",
    "branched_samples_before_2 = {}\n",
    "for class_to_sample in classes_01:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    sample = generate.generate_continuous_branched_samples(\n",
    "        branched_model_2, sde, class_to_sample,\n",
    "        lambda c, t: class_time_to_branch_tensor(c, t, branch_defs_012),\n",
    "        sampler=\"pc\", t_limit=t_limit, num_samples=1000, verbose=True\n",
    "    )\n",
    "    branched_samples_before_2[class_to_sample] = sample.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992ca21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model, for the specific branches only\n",
    "\n",
    "# Freeze all shared layers of the model, and freeze all task-specific\n",
    "# layers other than the ones we want to train\n",
    "for module_name in [\"layers\", \"time_embedders\"]:\n",
    "    for submodule in branched_model_2.get_submodule(module_name):\n",
    "        if len(submodule) == 1:\n",
    "            for p in submodule.parameters():\n",
    "                p.requires_grad = False\n",
    "        elif len(submodule) == len(branch_defs_012):\n",
    "            for i in range(len(submodule)):\n",
    "                if branch_map_inds[i] != -1:\n",
    "                    for p in submodule[i].parameters():\n",
    "                        p.requires_grad = False\n",
    "                else:\n",
    "                    for p in submodule[i].parameters():\n",
    "                        p.requires_grad = True\n",
    "        else:\n",
    "            raise ValueError(\"Found module list of length %d\" % len(submodule))\n",
    "submodule = branched_model_2.get_submodule(\"last_linears\")\n",
    "for i in range(len(submodule)):\n",
    "    if branch_map_inds[i] != -1:\n",
    "        for p in submodule[i].parameters():\n",
    "            p.requires_grad = False\n",
    "    else:\n",
    "        for p in submodule[i].parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "# Train\n",
    "train_continuous_model.train_ex.run(\n",
    "    \"train_branched_model\",\n",
    "    config_updates={\n",
    "        \"model\": branched_model_2,\n",
    "        \"sde\": sde,\n",
    "        \"data_loader\": data_loader_2,\n",
    "        \"class_time_to_branch_index\": lambda c, t: class_time_to_branch_tensor(c, t, branch_defs_012),\n",
    "        \"num_epochs\": 100,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"t_limit\": branch_defs_2[0][2],\n",
    "        \"loss_weighting_type\": \"empirical_norm\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the samples\n",
    "branched_samples_after = {}\n",
    "for class_to_sample in classes_012:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    sample = generate.generate_continuous_branched_samples(\n",
    "        branched_model_2, sde, class_to_sample,\n",
    "        lambda c, t: class_time_to_branch_tensor(c, t, branch_defs_012),\n",
    "        sampler=\"pc\", t_limit=t_limit, num_samples=1000, verbose=True\n",
    "    )\n",
    "    branched_samples_after[class_to_sample] = sample.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78ad98",
   "metadata": {},
   "source": [
    "#### Train label-guided model with only new label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c18892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the label-guided model\n",
    "label_guided_model_1 = model_util.load_model(\n",
    "    scrna_ae.LabelGuidedResNet,\n",
    "    os.path.join(models_base_path, \"scrna_covid_flu_continuous_labelguided_2classes/1/last_ckpt.pth\")\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ddc6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_samples_before = {}\n",
    "for class_to_sample in classes_012:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    sample = generate.generate_continuous_label_guided_samples(\n",
    "        label_guided_model_1, sde, class_to_sample,\n",
    "        lambda c: class_to_class_index_tensor(c, classes_012),\n",
    "        sampler=\"pc\", t_limit=t_limit, num_samples=1000, verbose=True\n",
    "    )\n",
    "    linear_samples_before[class_to_sample] = sample.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a3956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train on only new label\n",
    "train_continuous_model.train_ex.run(\n",
    "    \"train_label_guided_model\",\n",
    "    config_updates={\n",
    "        \"model\": label_guided_model_1,\n",
    "        \"sde\": sde,\n",
    "        \"data_loader\": data_loader_2,\n",
    "        \"class_to_class_index\": lambda c: class_to_class_index_tensor(c, classes_012),\n",
    "        \"num_epochs\": 10,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"t_limit\": t_limit,\n",
    "        \"loss_weighting_type\": \"empirical_norm\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af73f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_samples_after_newonly = {}\n",
    "for class_to_sample in classes_012:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    sample = generate.generate_continuous_label_guided_samples(\n",
    "        label_guided_model_1, sde, class_to_sample,\n",
    "        lambda c: class_to_class_index_tensor(c, classes_012),\n",
    "        sampler=\"pc\", t_limit=t_limit, num_samples=1000, verbose=True\n",
    "    )\n",
    "    linear_samples_after_newonly[class_to_sample] = sample.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e003f",
   "metadata": {},
   "source": [
    "#### Train label-guided model with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the label-guided model\n",
    "label_guided_model_2 = model_util.load_model(\n",
    "    scrna_ae.LabelGuidedResNet,\n",
    "    os.path.join(models_base_path, \"scrna_covid_flu_continuous_labelguided_2classes/1/last_ckpt.pth\")\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb65d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train on all data\n",
    "train_continuous_model.train_ex.run(\n",
    "    \"train_label_guided_model\",\n",
    "    config_updates={\n",
    "        \"model\": label_guided_model_2,\n",
    "        \"sde\": sde,\n",
    "        \"data_loader\": data_loader_012,\n",
    "        \"class_to_class_index\": lambda c: class_to_class_index_tensor(c, classes_012),\n",
    "        \"num_epochs\": 30,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"t_limit\": t_limit,\n",
    "        \"loss_weighting_type\": \"empirical_norm\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_samples_after_all = {}\n",
    "for class_to_sample in classes_012:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    sample = generate.generate_continuous_label_guided_samples(\n",
    "        label_guided_model_2, sde, class_to_sample,\n",
    "        lambda c: class_to_class_index_tensor(c, classes_012),\n",
    "        sampler=\"pc\", t_limit=t_limit, num_samples=1000, verbose=True\n",
    "    )\n",
    "    linear_samples_after_all[class_to_sample] = sample.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff25fc",
   "metadata": {},
   "source": [
    "#### Compute FIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b853d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample objects from the original dataset\n",
    "true_samples = {}\n",
    "for class_to_sample in classes_012:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    inds = np.where(dataset_012.cell_cluster == class_to_sample)[0]\n",
    "    sample_inds = np.random.choice(inds, size=1000, replace=False)\n",
    "    true_samples[class_to_sample] = dataset_012.data[sample_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d78307",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not latent_space:\n",
    "    dataset_with_ae = scrna_dataset.SingleCellDataset(data_file, autoencoder_path=autoencoder_path)\n",
    "\n",
    "def compute_fid(gen_samples, true_samples, latent=True):\n",
    "    if latent_space:\n",
    "        if latent:\n",
    "            return fid.compute_fid(\n",
    "                gen_samples,\n",
    "                dataset_01.encode_batch(torch.tensor(true_samples, device=DEVICE)).cpu().numpy()\n",
    "            )\n",
    "        else:\n",
    "            return fid.compute_fid(\n",
    "                dataset_01.decode_batch(torch.tensor(gen_samples, device=DEVICE)).cpu().numpy(),\n",
    "                true_samples\n",
    "            )\n",
    "    else:\n",
    "        gen_samples[gen_samples < 0] = 0  # Generated values should never be above 0\n",
    "        if latent:\n",
    "            return fid.compute_fid(\n",
    "                dataset_with_ae.encode_batch(torch.tensor(gen_samples, device=DEVICE)).cpu().numpy(),\n",
    "                dataset_with_ae.encode_batch(torch.tensor(true_samples, device=DEVICE)).cpu().numpy()\n",
    "            )\n",
    "        else:\n",
    "            return fid.compute_fid(\n",
    "                dataset_with_ae.decode_batch(dataset_with_ae.encode_batch(torch.tensor(gen_samples, device=DEVICE))).cpu().numpy(),\n",
    "                dataset_with_ae.decode_batch(dataset_with_ae.encode_batch(torch.tensor(true_samples, device=DEVICE))).cpu().numpy()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e69366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "branched_before_fids = {}\n",
    "branched_before_2_fids = {}\n",
    "branched_after_fids = {}\n",
    "linear_before_fids = {}\n",
    "linear_after_newonly_fids = {}\n",
    "linear_after_all_fids = {}\n",
    "\n",
    "latent = True\n",
    "\n",
    "for c in branched_samples_before.keys():\n",
    "    branched_before_fids[c] = compute_fid(branched_samples_before[c], true_samples[c], latent)\n",
    "for c in branched_samples_before_2.keys():\n",
    "    branched_before_2_fids[c] = compute_fid(branched_samples_before_2[c], true_samples[c], latent)\n",
    "for c in branched_samples_after.keys():\n",
    "    branched_after_fids[c] = compute_fid(branched_samples_after[c], true_samples[c], latent)\n",
    "for c in linear_samples_before.keys():\n",
    "    linear_before_fids[c] = compute_fid(linear_samples_before[c], true_samples[c], latent)\n",
    "for c in linear_samples_after_newonly.keys():\n",
    "    linear_after_newonly_fids[c] = compute_fid(linear_samples_after_newonly[c], true_samples[c], latent)\n",
    "for c in linear_samples_after_all.keys():\n",
    "    linear_after_all_fids[c] = compute_fid(linear_samples_after_all[c], true_samples[c], latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B-before\", branched_before_fids)\n",
    "print(\"B-before2\", branched_before_2_fids)\n",
    "print(\"B-after\", branched_after_fids)\n",
    "print(\"L-before\", linear_before_fids)\n",
    "print(\"L-afterone\", linear_after_newonly_fids)\n",
    "print(\"L-afterall\", linear_after_all_fids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
